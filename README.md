## **基于语义的搜索引擎**
### **写在前面**
这是一个关于美食做法的搜素引擎，它的特色在于语义搜索。这是研一上学期时学院里分配的一个工程实践任务（4人组），主要涉及到的技术有爬虫部分、语义分析部分和搜索部分。  
### **实现过程**
在实现这个搜索引擎过程中，使用了Python处理所有与数据有关的模块，PHP完成自然语言分析以及服务器的搭建，主要的重心放在了语义分析和爬虫部分了。
#### **数据部分**
在data文件中，存放了所有从<a href="http://www.meishichina.com" target="_blank">美食天下网</a>爬到的数据，以为对应的数据处理程序。数据的收集和处理，实现上都不是太难，但耗费了很多时间。最共抓取了大约5.5W条菜的记录，在此给贵网站带来的不便，致以深深的歉意。
#### **服务器部分**
这里包含了自然语言处理、数据库交互两部分。使用PHP实现了整个服务器框架，因为我没学过PHP，所以很多代码看起来很low。   
#### **自然语言处理**
因为这个工程重点在于语义分析，放在了lib文件夹中。关于语义分析，我了解的知识很少，现在在补充这方面的知识。  

我们的做法是先对用户的输入进行分词，这里使用的分词工具是<a href="http://www.xunsearch.com/scws/" target="_blank">scws</a>，使用了它的PHP扩展。其中我的一位队友正在完善scws的词典部分。  

然后根据分词的结果，对其进行**同义词扩展**，同义词词典**syno.db**位于**lib/nlp/db/**中，然后使用贝叶斯分类器，判断用户想搜索的类别。分类器的目的在于，为了确定对于用户的输入去匹配数据库中的哪个字段。然后依据事先计算的关联规则，把分词后的词条组合起来。

这里我曾尝试使用**LDA主题模型**完成对用户输入的浅层语义分析，但实际写出的代码效果并不好。一方面可能由于自己的语料太小、太狭隘，这可能会影响LDA模型训练的结果；还有一方面可能由于用于的搜索输入一般很小、很单一，只是简单依据欧式距离的远近来判断用户想查哪道菜，这误差会很大....  
#### **贝叶斯分类器**
语义分析是一个不断迭代不断升级的过程，这里我根据贝叶斯公式，写了一个关于**菜名、食材、类型**的分类器，效果不错，它位于**lib/nlp/nlp.php**中，计算的**先验概率**放在**lib/nlp/db/gather.txt**中。  
用户输入： 西红柿炒鸡蛋  
分词结果： 西红柿 炒 鸡蛋  
分类结果： 菜名

我在想，在这里使用贝叶斯分类器其实是不合适的。。。因为我提取的**特征之间并不是独立的**。假如说，  
用户输入：西红柿  
西红柿既可能属于**菜名**，又可能属于**食材**。  

这里我采用的解决办法是：计算每个类别的概率，若两者相差不大的情况下，同时返回两者。具体实现在**lib/nlp/nlp.php中**  
### **关联规则的计算**
关联规则的计算好坏直接影响了搜索结果的准确度，这里我尝试了2种关联的度量方法，一种是兴趣提升因子，一种是简单的计算两个词条同时出现在多少个记录中，取频率最高的前6个。测试发现第二种的关联度量方式更好。
## **LDA主题模型及推断过程**
这记录在我的博客中了<a href="http://willstudy.cn/blog/NLP/lda_implement.html" target="_blank">LDA的实现与理解</a>
## **总结**
一路下来真是学到了不少新的东西，接触到了机器学习的思想，学会了如何组织目录结构。。。受益匪浅～
